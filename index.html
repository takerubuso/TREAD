<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>聖徳太子なりきりAR（軽量版）</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            background-color: #000;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
        }
        canvas {
            position: absolute;
            transform: scaleX(-1); 
        }
        video { display: none; }
        
        /* 状態表示用のテキスト（右上） */
        #status {
            position: absolute;
            top: 10px;
            right: 10px;
            color: #0f0; /* 緑色 */
            font-family: monospace;
            font-size: 16px;
            background: rgba(0,0,0,0.8);
            padding: 10px;
            border-radius: 5px;
            z-index: 100;
            pointer-events: none;
            white-space: pre-wrap;
        }
    </style>
</head>
<body>
    <div id="status">起動準備中...</div>
    <video id="input_video"></video>
    <canvas id="output_canvas"></canvas>

    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/selfie_segmentation.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://pixijs.download/v7.x/pixi.min.js"></script>

    <script>
        // --- 設定 ---
        // ★もし画像が jpg ならここを 'face.jpg' に変えてください
        const IMAGE_PATH = 'face.png'; 
        const BLUR_STRENGTH = 10; // ぼかしを少し弱めて軽くする
        // ------------

        const videoElement = document.getElementById('input_video');
        const canvasElement = document.getElementById('output_canvas');
        const statusElement = document.getElementById('status');

        let faceMesh, selfieSegmentation, camera;
        let pixiApp, faceSprite, segmentationMaskSprite;
        let videoTexture, bgVideoSprite, fgVideoSprite;

        function log(msg) {
            statusElement.textContent = msg;
            console.log(msg);
        }

        function initPixi() {
            pixiApp = new PIXI.Application({
                view: canvasElement,
                width: window.innerWidth,
                height: window.innerHeight,
                transparent: true,
                resizeTo: window
            });

            videoTexture = PIXI.Texture.from(videoElement);

            // 奥：ぼかし背景
            bgVideoSprite = new PIXI.Sprite(videoTexture);
            bgVideoSprite.width = pixiApp.screen.width;
            bgVideoSprite.height = pixiApp.screen.height;
            bgVideoSprite.filters = [new PIXI.BlurFilter(BLUR_STRENGTH)];
            pixiApp.stage.addChild(bgVideoSprite);

            // 中：顔イラスト
            const faceContainer = new PIXI.Container();
            pixiApp.stage.addChild(faceContainer);
            
            faceSprite = new PIXI.Sprite(PIXI.Texture.from(IMAGE_PATH));
            faceSprite.anchor.set(0.5);
            faceSprite.visible = false; 
            faceContainer.addChild(faceSprite);

            // 手前：くっきり人物
            fgVideoSprite = new PIXI.Sprite(videoTexture);
            fgVideoSprite.width = pixiApp.screen.width;
            fgVideoSprite.height = pixiApp.screen.height;
            pixiApp.stage.addChild(fgVideoSprite);

            // マスク（最初は白＝全部表示）
            segmentationMaskSprite = new PIXI.Sprite(PIXI.Texture.WHITE);
            segmentationMaskSprite.width = pixiApp.screen.width;
            segmentationMaskSprite.height = pixiApp.screen.height;
            fgVideoSprite.mask = segmentationMaskSprite;

            // リサイズ対応
            window.addEventListener('resize', () => {
                const w = pixiApp.screen.width; const h = pixiApp.screen.height;
                bgVideoSprite.width = w; bgVideoSprite.height = h;
                fgVideoSprite.width = w; fgVideoSprite.height = h;
                segmentationMaskSprite.width = w; segmentationMaskSprite.height = h;
            });
        }

        function onFaceMeshResults(results) {
            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                log("稼働中: 顔認識OK");
                faceSprite.visible = true;
                const landmarks = results.multiFaceLandmarks[0];
                
                const nose = landmarks[1];
                const leftCheek = landmarks[234];
                const rightCheek = landmarks[454];

                const cx = nose.x * pixiApp.screen.width;
                const cy = nose.y * pixiApp.screen.height;
                faceSprite.position.set(cx, cy);

                const faceWidth = Math.hypot(
                    (rightCheek.x - leftCheek.x) * pixiApp.screen.width,
                    (rightCheek.y - leftCheek.y) * pixiApp.screen.height
                );
                faceSprite.scale.set((faceWidth / 400) * 2.0);

                const leftEye = landmarks[33];
                const rightEye = landmarks[263];
                faceSprite.rotation = Math.atan2(rightEye.y - leftEye.y, rightEye.x - leftEye.x);
            } else {
                log("稼働中: 顔を探しています...");
            }
        }

        function onSelfieSegmentationResults(results) {
            // マスク更新
            segmentationMaskSprite.texture = PIXI.Texture.from(results.segmentationMask);
        }

        async function start() {
            log("初期化中: 画面を作成...");
            initPixi();

            log("初期化中: 顔認識モデルをダウンロード中...(重いです)");
            faceMesh = new FaceMesh({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`});
            faceMesh.setOptions({
                maxNumFaces: 1,
                refineLandmarks: true,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });
            faceMesh.onResults(onFaceMeshResults);

            log("初期化中: 切り抜きモデルをダウンロード中...");
            selfieSegmentation = new SelfieSegmentation({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}`});
            selfieSegmentation.setOptions({ modelSelection: 1 });
            selfieSegmentation.onResults(onSelfieSegmentationResults);

            log("初期化中: カメラを起動します...");
            camera = new Camera(videoElement, {
                onFrame: async () => {
                    // 順番に処理（負荷軽減）
                    await faceMesh.send({image: videoElement});
                    await selfieSegmentation.send({image: videoElement});
                    videoTexture.update();
                },
                width: 640,  // 処理を軽くするために解像度を少し落とす
                height: 480
            });
            
            await camera.start();
            log("準備完了: 処理開始");
        }

        start();
    </script>
</body>
</html>
