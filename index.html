<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>聖徳太子なりきりAR（デバッグ版）</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            background-color: #000;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
        }
        canvas {
            position: absolute;
            transform: scaleX(-1); 
        }
        video { display: none; }
        #status {
            position: absolute;
            top: 10px;
            left: 10px;
            color: yellow;
            font-size: 20px;
            z-index: 100;
            background: rgba(0,0,0,0.5);
            padding: 10px;
            pointer-events: none;
        }
    </style>
</head>
<body>
    <div id="status">初期化中...<br>コンソールも確認してください</div>
    <video id="input_video"></video>
    <canvas id="output_canvas"></canvas>

    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/selfie_segmentation.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://pixijs.download/v7.x/pixi.min.js"></script>

    <script>
        const videoElement = document.getElementById('input_video');
        const canvasElement = document.getElementById('output_canvas');
        const statusElement = document.getElementById('status');

        let faceMesh, selfieSegmentation, camera;
        let pixiApp, faceSprite, segmentationMask, videoSprite;
        let debugSprite; // デバッグ確認用の画像

        function log(msg) {
            console.log(msg);
            statusElement.innerHTML = msg;
        }

        function initPixi() {
            pixiApp = new PIXI.Application({
                view: canvasElement,
                width: window.innerWidth,
                height: window.innerHeight,
                transparent: true,
                autoDensity: true,
                resolution: window.devicePixelRatio || 1
            });

            const videoTexture = PIXI.Texture.from(videoElement);
            videoSprite = new PIXI.Sprite(videoTexture);
            videoSprite.width = pixiApp.screen.width;
            videoSprite.height = pixiApp.screen.height;
            pixiApp.stage.addChild(videoSprite);
            
            const faceContainer = new PIXI.Container();
            pixiApp.stage.addChild(faceContainer);

            // 画像の読み込み確認
            // テスト用にネットの画像を使ってみる
const faceTexture = PIXI.Texture.from('https://pixijs.io/examples/examples/assets/bunny.png');
            
            // 本番用の顔スプライト
            faceSprite = new PIXI.Sprite(faceTexture);
            faceSprite.anchor.set(0.5);
            faceSprite.visible = false; 
            faceContainer.addChild(faceSprite);

            // ★デバッグ用：左上に小さく画像を出す（これが映れば画像読み込みは成功）
            debugSprite = new PIXI.Sprite(faceTexture);
            debugSprite.width = 100;
            debugSprite.height = 100;
            debugSprite.x = 50; 
            debugSprite.y = 50;
            pixiApp.stage.addChild(debugSprite); // マスクの外に置く

            segmentationMask = new PIXI.Sprite(PIXI.Texture.WHITE);
            segmentationMask.width = pixiApp.screen.width;
            segmentationMask.height = pixiApp.screen.height;
            faceContainer.mask = segmentationMask;

            log("Pixi初期化完了。画像を読み込みました。左上に小さい聖徳太子はいますか？");
        }

        function onFaceMeshResults(results) {
            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                log("顔を認識しています！");
                const landmarks = results.multiFaceLandmarks[0];
                faceSprite.visible = true;

                const nose = landmarks[1];
                const leftCheek = landmarks[234];
                const rightCheek = landmarks[454];

                const cx = nose.x * pixiApp.screen.width;
                const cy = nose.y * pixiApp.screen.height;
                faceSprite.position.set(cx, cy);

                const faceWidth = Math.hypot(
                    (rightCheek.x - leftCheek.x) * pixiApp.screen.width,
                    (rightCheek.y - leftCheek.y) * pixiApp.screen.height
                );
                const initialFaceWidth = 400; 
                const scale = (faceWidth / initialFaceWidth) * 2.0; 
                faceSprite.scale.set(scale);

                const leftEye = landmarks[33];
                const rightEye = landmarks[263];
                const mouthCenter = landmarks[13]; 
                const eyeCenterX = (leftEye.x + rightEye.x) / 2;
                const eyeCenterY = (leftEye.y + rightEye.y) / 2;
                const dx = mouthCenter.x - eyeCenterX;
                const dy = mouthCenter.y - eyeCenterY;
                const angle = Math.atan2(dy, dx) - Math.PI / 2;
                faceSprite.rotation = angle;

            } else {
                log("顔が見つかりません... カメラに近づいてください");
                faceSprite.visible = false;
            }
        }

        function onSelfieSegmentationResults(results) {
            const maskTexture = PIXI.Texture.from(results.segmentationMask);
            segmentationMask.texture = maskTexture;
        }

        async function start() {
            log("開始中...");
            initPixi();

            faceMesh = new FaceMesh({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`});
            faceMesh.setOptions({
                maxNumFaces: 1,
                refineLandmarks: true,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });
            faceMesh.onResults(onFaceMeshResults);

            selfieSegmentation = new SelfieSegmentation({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}`});
            selfieSegmentation.setOptions({ modelSelection: 1 });
            selfieSegmentation.onResults(onSelfieSegmentationResults);

            camera = new Camera(videoElement, {
                onFrame: async () => {
                    await faceMesh.send({image: videoElement});
                    await selfieSegmentation.send({image: videoElement});
                    videoSprite.texture.update();
                },
                width: 1280,
                height: 720
            });
            camera.start();
        }

        start();
    </script>
</body>
</html>
