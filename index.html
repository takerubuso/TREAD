<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>聖徳太子なりきりAR（口パク完成版）</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            background-color: #000;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
        }
        canvas {
            position: absolute;
            transform: scaleX(-1); 
        }
        video { display: none; }
        #status {
            position: absolute;
            top: 10px; right: 10px;
            color: #0f0; font-family: sans-serif; font-size: 14px;
            background: rgba(0,0,0,0.7); padding: 8px 12px;
            border-radius: 5px; z-index: 100; pointer-events: none;
        }
    </style>
</head>
<body>
    <div id="status">準備中...</div>
    <video id="input_video"></video>
    <canvas id="output_canvas"></canvas>

    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/selfie_segmentation.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://pixijs.download/v7.x/pixi.min.js"></script>

    <script>
        // =========== 設定エリア ===========
        const IMAGE_PATH = 'face.png'; 
        const FACE_SCALE = 1.0; // 顔の基本サイズ
        const BLUR_STRENGTH = 10; // 背景ぼかし強度

        // ★追加：口の開きやすさ（数値を上げると、少し開けただけで大きく反応します）
        const MOUTH_SENSITIVITY = 2.5; 
        // =================================

        const videoElement = document.getElementById('input_video');
        const statusElement = document.getElementById('status');
        let faceMesh, selfieSegmentation, camera;
        let pixiApp, faceSprite, segmentationMaskSprite;
        let videoTexture, bgVideoSprite, fgVideoSprite;

        function log(msg) { statusElement.textContent = msg; }

        function initPixi() {
            pixiApp = new PIXI.Application({
                view: document.getElementById('output_canvas'),
                width: window.innerWidth, height: window.innerHeight,
                transparent: true, resizeTo: window, autoDensity: true
            });
            videoTexture = PIXI.Texture.from(videoElement);

            // レイヤー構築
            bgVideoSprite = new PIXI.Sprite(videoTexture);
            bgVideoSprite.filters = [new PIXI.BlurFilter(BLUR_STRENGTH)];
            pixiApp.stage.addChild(bgVideoSprite);

            faceSprite = new PIXI.Sprite(PIXI.Texture.from(IMAGE_PATH));
            faceSprite.anchor.set(0.5); // 中心を基準に変形させる
            faceSprite.visible = false; 
            pixiApp.stage.addChild(faceSprite);

            fgVideoSprite = new PIXI.Sprite(videoTexture);
            pixiApp.stage.addChild(fgVideoSprite);
            segmentationMaskSprite = new PIXI.Sprite(PIXI.Texture.EMPTY);
            fgVideoSprite.mask = segmentationMaskSprite;

            window.addEventListener('resize', resizeAll);
            resizeAll();
        }

        function resizeAll() {
            const w = pixiApp.screen.width; const h = pixiApp.screen.height;
            if(bgVideoSprite) { bgVideoSprite.width = w; bgVideoSprite.height = h; }
            if(fgVideoSprite) { fgVideoSprite.width = w; fgVideoSprite.height = h; }
            if(segmentationMaskSprite) { segmentationMaskSprite.width = w; segmentationMaskSprite.height = h; }
        }

        // 顔認識結果の処理（ここに口パクのロジックを追加）
        function onFaceMeshResults(results) {
            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                log("稼働中: 顔認識OK");
                faceSprite.visible = true;
                const landmarks = results.multiFaceLandmarks[0];
                
                // 位置計算
                const nose = landmarks[1];
                faceSprite.position.set(nose.x * pixiApp.screen.width, nose.y * pixiApp.screen.height);

                // 基本サイズの計算
                const leftCheek = landmarks[234];
                const rightCheek = landmarks[454];
                const faceWidthPx = Math.hypot(
                    (rightCheek.x - leftCheek.x) * pixiApp.screen.width,
                    (rightCheek.y - leftCheek.y) * pixiApp.screen.height
                );
                const baseScale = (faceWidthPx / 512) * FACE_SCALE;

                // --- ★口の動き計算 ---
                const upperLip = landmarks[13]; // 上唇中央
                const lowerLip = landmarks[14]; // 下唇中央
                // 画面上での唇の距離を測る
                const mouthDist = Math.hypot(
                    (upperLip.x - lowerLip.x) * pixiApp.screen.width,
                    (upperLip.y - lowerLip.y) * pixiApp.screen.height
                );
                // 顔の大きさに対する口の開きの比率を計算
                let mouthRatio = mouthDist / faceWidthPx;
                // ノイズ除去（口を閉じていても少し距離があるので、それを引く）
                mouthRatio = Math.max(0, mouthRatio - 0.02);

                // 縦方向のスケールにのみ、口の開き分を加算する
                const scaleY = baseScale * (1 + mouthRatio * MOUTH_SENSITIVITY);
                
                // スケール適用（横は基本通り、縦は口に合わせて伸縮）
                faceSprite.scale.set(baseScale, scaleY);
                // ----------------------

                // 傾き計算
                const leftEye = landmarks[33]; const rightEye = landmarks[263];
                faceSprite.rotation = Math.atan2(rightEye.y - leftEye.y, rightEye.x - leftEye.x);
            } else {
                faceSprite.visible = false;
            }
        }

        function onSelfieSegmentationResults(results) {
            segmentationMaskSprite.texture = PIXI.Texture.from(results.segmentationMask);
            resizeAll(); // マスクサイズがリセットされるのを防ぐ
        }

        async function start() {
            log("初期化中..."); initPixi();
            faceMesh = new FaceMesh({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`});
            faceMesh.setOptions({ maxNumFaces: 1, refineLandmarks: true, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });
            faceMesh.onResults(onFaceMeshResults);
            selfieSegmentation = new SelfieSegmentation({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}`});
            selfieSegmentation.setOptions({ modelSelection: 1 });
            selfieSegmentation.onResults(onSelfieSegmentationResults);

            log("カメラ起動...");
            camera = new Camera(videoElement, {
                onFrame: async () => {
                    // 負荷分散のため交互に処理
                    if (pixiApp.ticker.lastTime % 2 === 0) await faceMesh.send({image: videoElement});
                    else await selfieSegmentation.send({image: videoElement});
                    videoTexture.update();
                }, width: 640, height: 480
            });
            await camera.start();
            log("AIモデル読み込み中...");
        }
        start();
    </script>
</body>
</html>
